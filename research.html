<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Research Work | Parth Bhalerao</title>
  <link rel="stylesheet" href="assets/css/style.css" />
  <script defer src="assets/js/script.js"></script>
</head>
<body>
  <!-- Navbar -->
  <header>
    <nav class="navbar">
      <div class="logo">PB</div>
      <ul class="nav-links">
        <li><a href="index.html">Home</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="research.html" class="active">Research</a></li>
        <li><a href="ai-ml.html">AI/ML</a></li>
        <li><a href="software.html">Software</a></li>
        <li><a href="education.html">Education</a></li>
        <li><a href="experience.html">Experience</a></li>
        <li><a href="youtube.html">YouTube</a></li>
        <li><a href="dsa.html">DSA</a></li>
        <li><a href="blogs.html">Blogs</a></li>
        <li><a href="certifications.html">Certifications</a></li>
        <li><a href="notes.html">Notes</a></li>
      </ul>
      <div class="hamburger">&#9776;</div>
    </nav>
  </header>

  <main class="content">
    <h1>Research Work</h1>

    <!-- Research cards container -->
    <section class="research-grid">
      
      <!-- Card 6 -->
        <article class="research-card">
        <h2 class="research-title">
            Mentorship for All: Multi-Agent Multilingual Long-Form Video Question Answering for Mentorship Applications
        </h2>

        <div class="research-media">
            <img
            src="assets/img/rsrch/6.png"
            alt="Mentorship for All research figure"
            class="fade-in-on-scroll"
            loading="lazy"
            />
        </div>

        <p class="research-meta">
            <strong>Published:</strong> Under Review â€“ Experimentation in progress, release soon
        </p>

        <p class="research-abstract">
            This research introduces a multi-agent framework for multilingual question-answering that efficiently extracts insights from long-form video content like podcasts and mentorship sessions. By using specialized agents for tasks like summarization and filtering, the framework significantly outperforms a single-agent baseline. The system processes audio directly from sources in languages including English, Romanian, and Marathi, making knowledge from global mentors more accessible and improving answer faithfulness by over 1.6 points on a five-point scale.
        </p>

        <div class="research-links">
            <a class="btn-lite" href="#" target="_blank" rel="noopener">ðŸ”— Read Paper</a>
        </div>
        </article>
    
      <!-- Card 1 -->
      <article class="research-card">
        <h2 class="research-title">
          MoSAIG: Multi-Agent Multimodal Models for Multicultural Text to Image Generation
        </h2>

        <div class="research-media">
          <img
            src="assets/img/rsrch/1.png"
            alt="MoSAIG research figure"
            class="fade-in-on-scroll"
            loading="lazy"
          />
        </div>

        <p class="research-meta"><strong>Published:</strong> Under-Review 2025</p>

        <p class="research-abstract">
          This paper presents MosAIG, a multi-agent framework leveraging LLMs with distinct cultural personas to
          enhance multicultural image generation. The authors contribute a dataset of 9,000 images spanning diverse
          countries, age groups, genders, landmarks, and languages. Experiments demonstrate that multi-agent
          interactions outperform single-model approaches across multiple evaluation metrics, offering new insights
          for culturally inclusive AI systems. Dataset and models are released publicly.
        </p>

        <div class="research-links">
          <a class="btn-lite" href="https://arxiv.org/pdf/2502.15972?" target="_blank" rel="noopener">ðŸ”— Read Paper</a>
        </div>
      </article>

      <!-- Card 2 -->
        <article class="research-card">
        <h2 class="research-title">
            ECG Classification Using Machine Learning on Wave Samples for the Indian Population
        </h2>

        <div class="research-media">
            <img
            src="assets/img/rsrch/2.png"
            alt="ECG Classification research figure"
            class="fade-in-on-scroll"
            loading="lazy"
            />
        </div>

        <p class="research-meta">
            <strong>Published:</strong> 2023 â€“ IEEE International Conference on Advancement in Computation & Computer Technologies (InCACCT)
        </p>

        <p class="research-abstract">
            This study proposes machine learning models for ECG rhythm classification tailored to the Indian population, using only 3 leads instead of the conventional 12, thereby reducing cost and complexity. The models classify cardiac rhythms as normal or abnormal directly from ECG wave samples. Multiple algorithms are compared for accuracy, using a dataset collected from hospitals in Nagpur city, making the work both practical and population-specific.
        </p>

        <div class="research-links">
            <a class="btn-lite" href="https://ieeexplore.ieee.org/document/10141762" target="_blank" rel="noopener">ðŸ”— Read Paper</a>
        </div>
        </article>

        <!-- Card 3 -->
        <article class="research-card">
        <h2 class="research-title">
            Design and Implementation of a Dynamic Traffic Signal System with Digital Circuit and IoT Integration for Efficient Traffic Management
        </h2>

        <div class="research-media">
            <img
            src="assets/img/rsrch/3.png"
            alt="Dynamic Traffic Signal System research figure"
            class="fade-in-on-scroll"
            loading="lazy"
            />
        </div>

        <p class="research-meta">
            <strong>Published:</strong> 2023 â€“ IEEE IIT-Delhi Top Conference, 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)
        </p>

        <p class="research-abstract">
            This research proposes a dynamic, sensor-based traffic signal system to overcome inefficiencies of static traffic management in India. The system adapts signal timing to real-time traffic density and incorporates an IoT-based emergency override for ambulances and VIP movement. A decoder-driven digital circuit, implemented in Verilog and simulated with a Python GUI, enables multiple active lanes without interference. Results show improved traffic flow, reduced congestion, and faster emergency response, offering a scalable solution for modern cities.
        </p>

        <div class="research-links">
            <a class="btn-lite" href="https://ieeexplore.ieee.org/document/10306612" target="_blank" rel="noopener">ðŸ”— Read Paper</a>
        </div>
        </article>

        <!-- Card 4 -->
        <article class="research-card">
        <h2 class="research-title">
            Performance Analysis of the YOLOv5 Algorithm for American Sign Language Detection
        </h2>

        <div class="research-media">
            <img
            src="assets/img/rsrch/4.png"
            alt="YOLOv5 ASL Detection research figure"
            class="fade-in-on-scroll"
            loading="lazy"
            />
        </div>

        <p class="research-meta">
            <strong>Published:</strong> SSRN Journal, 2022
        </p>

        <p class="research-abstract">
            This paper analyzes the YOLOv5 algorithm for American Sign Language (ASL) detection, evaluating its performance across TensorFlow and PyTorch frameworks on devices such as Intel processors and Raspberry Pi. The study identifies alphabets with higher false positive/negative rates and compares model accuracy under different setups. Results indicate that Raspberry Pi with TensorFlow fp16 at 320 image size and weight is the most efficient configuration for practical deployment.
        </p>

        <div class="research-links">
            <a class="btn-lite" href="https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=4363738" target="_blank" rel="noopener">ðŸ”— Read Paper</a>
        </div>
        </article>

        <!-- Card 5 -->
        <article class="research-card">
        <h2 class="research-title">
            Point of Care Device for Measurement of Vital Parameters
        </h2>

        <div class="research-media">
            <img
            src="assets/img/rsrch/5.png"
            alt="Point of Care Device research figure"
            class="fade-in-on-scroll"
            loading="lazy"
            />
        </div>

        <p class="research-meta">
            <strong>Published:</strong> Springer, 2023 â€“ Smart Trends in Computation and Communication (SmartCom 2023 International Conference)
        </p>

        <p class="research-abstract">
            This research proposes a solution to improve healthcare access in remote areas by developing a portable, non-invasive device. This device is capable of measuring vital health parameters like body temperature, ECG, and PPG, and then calculating heart rate and blood pressure. The study focuses on creating a compact, low-cost prototype to enable early diagnosis and reduce the need for patients to travel to city hospitals, with further recommendations for improving accuracy. <strong>(Patent Granted)</strong>
        </p>

        <div class="research-links">
            <a class="btn-lite" href="https://link.springer.com/chapter/10.1007/978-981-99-0838-7_27" target="_blank" rel="noopener">ðŸ”— Read Paper</a>
        </div>
        </article>


      <!-- Duplicate the <article> block above for more items -->
    </section>
  </main>

  <!-- Footer -->
  <footer>
    <div class="socials">
      <a href="https://www.linkedin.com/in/parthvb/" target="_blank">
        <img src="assets/img/icons/linkedin.png" alt="LinkedIn">
      </a>
      <a href="mailto:pbhalerao@scu.edu" target="_blank">
        <img src="assets/img/icons/mail.png" alt="Email">
      </a>
      <a href="https://scholar.google.com/citations?user=5cUuFPoAAAAJ&hl=en" target="_blank">
        <img src="assets/img/icons/scholar.png" alt="Google Scholar">
      </a>
      <a href="https://github.com/pvbgeek" target="_blank">
        <img src="assets/img/icons/git.png" alt="GitHub">
      </a>
      <a href="https://www.youtube.com/@pvb-geek" target="_blank">
        <img src="assets/img/icons/youtube.png" alt="YouTube">
      </a>
    </div>
    <p>&copy; 2025 Parth Bhalerao | All Rights Reserved</p>
  </footer>
</body>
</html>
